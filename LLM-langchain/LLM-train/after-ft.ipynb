{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig,AutoModel,AutoTokenizer\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ChatGLMForConditionalGeneration were not initialized from the model checkpoint at /root/autodl-tmp/chatglm2-6b-int4 and are newly initialized: ['transformer.prefix_encoder.embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_src = r\"/root/autodl-tmp/chatglm2-6b-int4\"\n",
    "CHECKPOINT_PATH = r\"/root/autodl-tmp/fix-helper/LLM-langchain/LLM-train/ptuning/output/adgen-chatglm2-6b-pt-128-2e-2/checkpoint-1000\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_src,trust_remote_code=True)\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_src, trust_remote_code=True, pre_seq_len=128)\n",
    "model = AutoModel.from_pretrained(model_src, config=config, trust_remote_code=True)\n",
    "prefix_state_dict = torch.load(os.path.join(CHECKPOINT_PATH, \"pytorch_model.bin\"))\n",
    "new_prefix_state_dict = {}\n",
    "for k, v in prefix_state_dict.items():\n",
    "    if k.startswith(\"transformer.prefix_encoder.\"):\n",
    "        new_prefix_state_dict[k[len(\"transformer.prefix_encoder.\"):]] = v\n",
    "model.transformer.prefix_encoder.load_state_dict(new_prefix_state_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out the following line if you don't use quantization\n",
    "model = model.quantize(4)\n",
    "model = model.cuda()\n",
    "model = model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the touchpad is not responding, you should first check if the touchpad driver is installed correctly through the settings. Open settings and look for 'Samsung Update,' then find 'Touchpad Driver' to ensure the touchpad is installed. If installed, it will show ' installed' in the text menu. If that doesn't work, try using a keyboard or touchpad with a finger to test the touchpad's touch sensitivity. If it feels hard to touch, it may be faulty or defective and need to replace.\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"My Samsung laptop's touchpad is not working properly, what should I do?\", history=[])\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
